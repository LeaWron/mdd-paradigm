# è®¤åŒç‡: è®¤åŒæ•°é‡ / æ€»æ•°é‡
# åå‘: ç§¯æè®¤åŒç‡ - æ¶ˆæè®¤åŒç‡
# æ¶ˆæRT - ç§¯æRT
# è®¤åŒRT - ä¸è®¤åŒRT
# æ¶ˆæintensity - ç§¯æintensity
from pathlib import Path

import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import plotly.subplots as sp
import polars as pl
from scipy import stats

from psycho.analysis.utils import extract_trials_by_block


# ä¸»åˆ†æå‡½æ•°
def analyze_self_reference_data(df, target_blocks=None, block_col="block_index"):
    print("=" * 60)

    # 1. å¦‚æœæŒ‡å®šäº†ç›®æ ‡åŒºå—ï¼Œæå–è¯¥åŒºå—çš„æ•°æ®
    if target_blocks is not None:
        print(f"æå–åŒºå— {target_blocks} çš„æ•°æ®...")
        df_analysis = extract_trials_by_block(
            df,
            target_block_indices=target_blocks,
            block_col=block_col,
            fill_na=True,
        )
        print(f"æå–åæ•°æ®å½¢çŠ¶: {df_analysis.shape}")
    else:
        df_analysis = df.clone()
        print(f"ä½¿ç”¨æ‰€æœ‰æ•°æ®ï¼Œå½¢çŠ¶: {df_analysis.shape}")

    # 2. åŸºç¡€ä¿¡æ¯
    print("æ•°æ®åŸºæœ¬ä¿¡æ¯:")
    print(f"æ€»è¡Œæ•°: {df_analysis.height}")
    print(f"åˆ—æ•°: {df_analysis.width}")
    print(f"åˆ—å: {', '.join(df_analysis.columns)}")

    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ["stim_word", "response", "rt", "intensity"]
    missing_columns = [
        col for col in required_columns if col not in df_analysis.columns
    ]
    if missing_columns:
        print(f"ï¸  è­¦å‘Š: ç¼ºå°‘å¿…è¦åˆ— {missing_columns}")
        return None

    # 3. åŸºç¡€ç»Ÿè®¡è®¡ç®—
    print("\n åŸºç¡€ç»Ÿè®¡:")

    # æ€»è¯•æ¬¡å’ŒYesæ¯”ä¾‹
    total_trials = df_analysis.height
    yes_count = df_analysis.filter(pl.col("response") == "yes").height
    yes_proportion = yes_count / total_trials if total_trials > 0 else 0

    print(f"æ€»è¯•æ¬¡æ•°: {total_trials}")
    print(f"Yesååº”æ•°: {yes_count}")
    print(f"Yesæ¯”ä¾‹: {yes_proportion:.2%}")

    # ååº”æ—¶ç»Ÿè®¡ (è½¬æ¢ä¸ºæ¯«ç§’)
    df_analysis = df_analysis.with_columns((pl.col("rt") * 1000).alias("rt_ms"))

    rt_stats = df_analysis.select(
        [
            pl.col("rt_ms").mean().alias("mean_rt"),
            pl.col("rt_ms").std().alias("std_rt"),
            pl.col("rt_ms").median().alias("median_rt"),
            pl.col("rt_ms").min().alias("min_rt"),
            pl.col("rt_ms").max().alias("max_rt"),
        ]
    )

    print("\nï¸ ååº”æ—¶ç»Ÿè®¡ (æ¯«ç§’):")
    print(f"å‡å€¼: {rt_stats['mean_rt'][0]:.1f} ms")
    print(f"æ ‡å‡†å·®: {rt_stats['std_rt'][0]:.1f} ms")
    print(f"ä¸­ä½æ•°: {rt_stats['median_rt'][0]:.1f} ms")
    print(f"èŒƒå›´: {rt_stats['min_rt'][0]:.0f} - {rt_stats['max_rt'][0]:.0f} ms")

    # 4. æŒ‰ååº”ç±»å‹åˆ†ç»„åˆ†æ
    response_stats = (
        df_analysis.group_by("response")
        .agg(
            [
                pl.col("rt_ms").mean().alias("mean_rt"),
                pl.col("rt_ms").std().alias("std_rt"),
                pl.col("intensity").mean().alias("mean_intensity"),
                pl.col("intensity").std().alias("std_intensity"),
                pl.count().alias("count"),
            ]
        )
        .sort("response")
    )

    print("\n æŒ‰ååº”ç±»å‹åˆ†ç»„ç»Ÿè®¡:")
    print(response_stats)

    # 5. å¼ºåº¦è¯„åˆ†åˆ†æ
    print("\n å¼ºåº¦è¯„åˆ†åˆ†æ:")
    intensity_stats = df_analysis.select(
        [
            pl.col("intensity").mean().alias("mean_intensity"),
            pl.col("intensity").std().alias("std_intensity"),
            pl.col("intensity").min().alias("min_intensity"),
            pl.col("intensity").max().alias("max_intensity"),
            pl.col("intensity").median().alias("median_intensity"),
        ]
    )

    print(
        f"æ•´ä½“å¼ºåº¦è¯„åˆ†: {intensity_stats['mean_intensity'][0]:.2f} Â± {intensity_stats['std_intensity'][0]:.2f}"
    )

    # 6. ä¸Rogersæ–‡çŒ®æ•°æ®æ¯”è¾ƒ
    rogers_ref = {
        "mean_rt": 2941,  # æ¯«ç§’
        "yes_rt": 3194,
        "no_rt": 2689,
        "yes_proportion": 0.613,  # 61.3%
        "recall_rate": 0.32,  # æ ¡æ­£åçš„å›å¿†ç‡
    }

    # æå–å½“å‰æ•°æ®
    your_data = {
        "mean_rt": rt_stats["mean_rt"][0],
        "yes_rt": response_stats.filter(pl.col("response") == "yes")["mean_rt"][0],
        "no_rt": response_stats.filter(pl.col("response") == "no")["mean_rt"][0],
        "yes_proportion": yes_proportion,
    }

    print("\nğŸ“š ä¸ Rogers et al. (1977) æ¯”è¾ƒ:")
    print(f"å¹³å‡RT: {your_data['mean_rt']:.0f} ms | æ–‡çŒ®: {rogers_ref['mean_rt']} ms")
    print(
        f"å·®å¼‚: {(your_data['mean_rt'] - rogers_ref['mean_rt']):+.0f} ms ({((your_data['mean_rt'] / rogers_ref['mean_rt']) - 1):+.1%})"
    )
    print(
        f"\nYesååº”RT: {your_data['yes_rt']:.0f} ms | æ–‡çŒ®: {rogers_ref['yes_rt']} ms"
    )
    print(f"Noååº”RT: {your_data['no_rt']:.0f} ms | æ–‡çŒ®: {rogers_ref['no_rt']} ms")
    print(
        f"\nYesæ¯”ä¾‹: {your_data['yes_proportion']:.1%} | æ–‡çŒ®: {rogers_ref['yes_proportion']:.1%}"
    )

    # 7. ç»Ÿè®¡æ£€éªŒ
    print("\nğŸ“Š ç»Ÿè®¡æ£€éªŒ:")

    # Yes vs Noååº”æ—¶å·®å¼‚
    yes_rt = df_analysis.filter(pl.col("response") == "yes")["rt_ms"].to_numpy()
    no_rt = df_analysis.filter(pl.col("response") == "no")["rt_ms"].to_numpy()

    if len(yes_rt) > 1 and len(no_rt) > 1:
        t_stat_rt, p_value_rt = stats.ttest_ind(yes_rt, no_rt, equal_var=False)
        print(f"ååº”æ—¶å·®å¼‚ (Yes vs No): t = {t_stat_rt:.2f}, p = {p_value_rt:.4f}")

        # æ•ˆåº”é‡ (Cohen's d)
        pooled_std = np.sqrt((np.var(yes_rt, ddof=1) + np.var(no_rt, ddof=1)) / 2)
        cohens_d = (np.mean(yes_rt) - np.mean(no_rt)) / pooled_std
        print(f"æ•ˆåº”é‡ (Cohen's d): {cohens_d:.2f}")
    else:
        print("æ ·æœ¬é‡ä¸è¶³è¿›è¡Œååº”æ—¶tæ£€éªŒ")

    # Yes vs Noå¼ºåº¦å·®å¼‚
    yes_intensity = df_analysis.filter(pl.col("response") == "yes")[
        "intensity"
    ].to_numpy()
    no_intensity = df_analysis.filter(pl.col("response") == "no")[
        "intensity"
    ].to_numpy()

    if len(yes_intensity) > 1 and len(no_intensity) > 1:
        t_stat_int, p_value_int = stats.ttest_ind(
            yes_intensity, no_intensity, equal_var=False
        )
        print(f"å¼ºåº¦å·®å¼‚ (Yes vs No): t = {t_stat_int:.2f}, p = {p_value_int:.4f}")
    else:
        print("æ ·æœ¬é‡ä¸è¶³è¿›è¡Œå¼ºåº¦tæ£€éªŒ")

    # 8. ç›¸å…³æ€§åˆ†æ
    print("\n ç›¸å…³æ€§åˆ†æ:")

    # æ•´ä½“RTä¸å¼ºåº¦ç›¸å…³
    overall_corr = df_analysis.select(
        [pl.corr("rt_ms", "intensity").alias("correlation")]
    )
    print(f"æ•´ä½“RT-å¼ºåº¦ç›¸å…³: r = {overall_corr['correlation'][0]:.3f}")

    # åˆ†ååº”ç±»å‹çš„ç›¸å…³
    for resp in ["yes", "no"]:
        subset = df_analysis.filter(pl.col("response") == resp)
        if subset.height > 2:
            corr = subset.select([pl.corr("rt_ms", "intensity").alias("correlation")])
            print(
                f"{resp.capitalize()}ååº”RT-å¼ºåº¦ç›¸å…³: r = {corr['correlation'][0]:.3f}"
            )

    # 9. è¯æ€§åˆ†æï¼ˆå¦‚æœå­˜åœ¨stim_typeåˆ—ï¼‰
    if "stim_type" in df_analysis.columns:
        print("\n è¯æ€§åˆ†æ:")
        stim_type_stats = (
            df_analysis.group_by("stim_type")
            .agg(
                [
                    pl.col("response")
                    .filter(pl.col("response") == "yes")
                    .count()
                    .alias("yes_count"),
                    pl.col("response").count().alias("total_count"),
                    pl.col("rt_ms").mean().alias("mean_rt"),
                    pl.col("intensity").mean().alias("mean_intensity"),
                ]
            )
            .with_columns(
                [(pl.col("yes_count") / pl.col("total_count")).alias("yes_proportion")]
            )
        )

        print(stim_type_stats)

    # 10. å®éªŒæœ‰æ•ˆæ€§è¯„ä¼°
    print("\n" + "=" * 60)
    print(" å®éªŒæœ‰æ•ˆæ€§è¯„ä¼°")
    print("=" * 60)

    # è¯„ä¼°æ ‡å‡†
    criteria = {
        "rt_within_range": rogers_ref["mean_rt"] * 0.8
        < your_data["mean_rt"]
        < rogers_ref["mean_rt"] * 1.2,
        "yes_rt_greater": your_data["yes_rt"] > your_data["no_rt"],
        "yes_proportion_reasonable": 0.3 < your_data["yes_proportion"] < 0.8,
        "yes_intensity_greater": None,
    }

    # æ£€æŸ¥å¼ºåº¦å·®å¼‚
    if len(yes_intensity) > 0 and len(no_intensity) > 0:
        criteria["yes_intensity_greater"] = np.mean(yes_intensity) > np.mean(
            no_intensity
        )

    print("\nè¯„ä¼°æ ‡å‡†:")
    print(
        "1. ååº”æ—¶åœ¨åˆç†èŒƒå›´å†… (2941Â±20%): ",
        f"{'âœ“' if criteria['rt_within_range'] else 'âœ—'} ({your_data['mean_rt']:.0f} ms)",
    )
    print(
        "2. Yesååº”æ—¶ > Noååº”æ—¶: ",
        f"{'âœ“' if criteria['yes_rt_greater'] else 'âœ—'} (Yes: {your_data['yes_rt']:.0f} ms, No: {your_data['no_rt']:.0f} ms)",
    )
    print(
        "3. Yesæ¯”ä¾‹åˆç† (30-80%): ",
        f"{'âœ“' if criteria['yes_proportion_reasonable'] else 'âœ—'} ({your_data['yes_proportion']:.1%})",
    )
    if criteria["yes_intensity_greater"] is not None:
        print(
            "4. Yesè¯å¼ºåº¦ > Noè¯å¼ºåº¦: ",
            f"{'âœ“' if criteria['yes_intensity_greater'] else 'âœ—'}",
        )

    # æ€»ç»“è¯„ä¼°
    pass_count = sum(
        [1 for v in criteria.values() if v is True or (v is not None and v)]
    )
    total_criteria = len([v for v in criteria.values() if v is not None])

    print(f"\næœ‰æ•ˆæ€§è¯„ä¼°ç»“æœ: {pass_count}/{total_criteria} é¡¹é€šè¿‡")

    if pass_count == total_criteria:
        print(" å®éªŒæ•°æ®è¡¨ç°å‡ºä¼˜ç§€çš„æœ‰æ•ˆæ€§ï¼Œå®Œå…¨ç¬¦åˆè‡ªæˆ‘å‚ç…§ç¼–ç ä»»åŠ¡çš„é¢„æœŸæ¨¡å¼ã€‚")
    elif pass_count >= total_criteria - 1:
        print(" å®éªŒæ•°æ®è¡¨ç°å‡ºè‰¯å¥½çš„æœ‰æ•ˆæ€§ï¼ŒåŸºæœ¬ç¬¦åˆé¢„æœŸæ¨¡å¼ã€‚")
    elif pass_count >= total_criteria - 2:
        print("ï¸  å®éªŒæ•°æ®åŸºæœ¬æœ‰æ•ˆï¼Œä½†éƒ¨åˆ†æŒ‡æ ‡åç¦»é¢„æœŸï¼Œéœ€åœ¨è®¨è®ºä¸­è¯´æ˜ã€‚")
    else:
        print(" å®éªŒæ•°æ®æœ‰æ•ˆæ€§ä¸è¶³ï¼Œå»ºè®®æ£€æŸ¥å®éªŒç¨‹åºæˆ–æ•°æ®å¤„ç†ã€‚")

    # 11. åˆ›å»ºå¯è§†åŒ–
    print("\nï¸  æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    create_visualizations(df_analysis, your_data, rogers_ref)

    # 12. ä¿å­˜æ±‡æ€»ç»“æœ
    summary_df = create_summary_dataframe(
        df_analysis, your_data, rogers_ref, yes_intensity, no_intensity, overall_corr
    )

    filename = "self_reference_analysis_summary.csv"

    summary_df.write_csv(filename)
    print(f"\n ç»“æœå·²ä¿å­˜åˆ°: {filename}")

    return summary_df


def create_visualizations(df, your_data, rogers_ref):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""

    # è½¬æ¢ä¸ºpandasç”¨äºPlotlyï¼ˆå¦‚æœæ•°æ®é‡ä¸å¤§ï¼‰
    if df.height < 10000:  # å®‰å…¨é˜ˆå€¼
        df_pd = df.to_pandas()
    else:
        print("ï¸  æ•°æ®é‡è¿‡å¤§ï¼Œéƒ¨åˆ†å¯è§†åŒ–å¯èƒ½è¢«è·³è¿‡")
        df_pd = df.head(1000).to_pandas()

    # 1. ååº”æ—¶åˆ†å¸ƒå›¾
    fig1 = px.histogram(
        df_pd,
        x="rt_ms",
        color="response",
        nbins=30,
        title="ååº”æ—¶åˆ†å¸ƒ",
        labels={"rt_ms": "ååº”æ—¶ (ms)", "count": "é¢‘æ•°"},
        opacity=0.7,
        barmode="overlay",
    )
    fig1.update_layout(
        xaxis_range=[0, df["rt_ms"].max() * 1.1], template="plotly_white"
    )
    fig1.show()

    # 2. ååº”æ—¶ä¸å¼ºåº¦æ•£ç‚¹å›¾
    fig2 = px.scatter(
        df_pd,
        x="rt_ms",
        y="intensity",
        color="response",
        title="ååº”æ—¶ä¸å¼ºåº¦å…³ç³»",
        labels={"rt_ms": "ååº”æ—¶ (ms)", "intensity": "å¼ºåº¦è¯„åˆ† (0-10)"},
        hover_data=["stim_word"],
        trendline="ols",
    )
    fig2.update_layout(template="plotly_white")
    fig2.show()

    # 3. ä¸æ–‡çŒ®æ¯”è¾ƒçš„æ¡å½¢å›¾
    comparison_data = {
        "æŒ‡æ ‡": ["å¹³å‡ååº”æ—¶", "Yesååº”æ—¶", "Noååº”æ—¶", "Yesæ¯”ä¾‹"],
        "ä½ çš„å®éªŒ": [
            your_data["mean_rt"],
            your_data["yes_rt"],
            your_data["no_rt"],
            your_data["yes_proportion"] * 100,  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        ],
        "Rogers(1977)": [
            rogers_ref["mean_rt"],
            rogers_ref["yes_rt"],
            rogers_ref["no_rt"],
            rogers_ref["yes_proportion"] * 100,
        ],
    }

    fig3 = go.Figure()

    # æ·»åŠ ä½ çš„æ•°æ®
    fig3.add_trace(
        go.Bar(
            name="ä½ çš„å®éªŒ",
            x=comparison_data["æŒ‡æ ‡"],
            y=comparison_data["ä½ çš„å®éªŒ"],
            marker_color="indianred",
            text=[
                f"{y:.0f}" if i < 3 else f"{y:.1f}%"
                for i, y in enumerate(comparison_data["ä½ çš„å®éªŒ"])
            ],
            textposition="auto",
        )
    )

    # æ·»åŠ æ–‡çŒ®æ•°æ®
    fig3.add_trace(
        go.Bar(
            name="Rogers(1977)",
            x=comparison_data["æŒ‡æ ‡"],
            y=comparison_data["Rogers(1977)"],
            marker_color="lightseagreen",
            text=[
                f"{y:.0f}" if i < 3 else f"{y:.1f}%"
                for i, y in enumerate(comparison_data["Rogers(1977)"])
            ],
            textposition="auto",
        )
    )

    fig3.update_layout(
        title="ä¸ç»å…¸ç ”ç©¶æ¯”è¾ƒ",
        xaxis_title="æŒ‡æ ‡",
        yaxis_title="æ•°å€¼",
        barmode="group",
        template="plotly_white",
        yaxis=dict(title="ååº”æ—¶(ms) / æ¯”ä¾‹(%)", tickformat=",d"),
    )
    fig3.show()

    # 4. å¼ºåº¦è¯„åˆ†åˆ†å¸ƒ
    if "stim_type" in df.columns:
        fig4 = px.box(
            df_pd,
            x="response",
            y="intensity",
            color="stim_type",
            title="å¼ºåº¦è¯„åˆ†åˆ†å¸ƒ",
            labels={"response": "ååº”ç±»å‹", "intensity": "å¼ºåº¦è¯„åˆ† (0-10)"},
            points="all",
        )
        fig4.update_layout(template="plotly_white")
        fig4.show()

    # 5. ååº”æ—¶åºåˆ—å›¾
    if "trial_index" in df.columns:
        df_seq = df.with_columns(pl.Series("trial_order", range(df.height)))

        fig5 = px.line(
            df_seq.to_pandas(),
            x="trial_order",
            y="rt_ms",
            color="response",
            title="ååº”æ—¶åºåˆ—å˜åŒ–",
            labels={"trial_order": "è¯•æ¬¡é¡ºåº", "rt_ms": "ååº”æ—¶ (ms)"},
            hover_data=["stim_word", "intensity"],
        )
        fig5.update_layout(template="plotly_white")

        # æ·»åŠ ç§»åŠ¨å¹³å‡çº¿
        for resp in ["yes", "no"]:
            subset = df_seq.filter(pl.col("response") == resp)
            if subset.height > 5:
                window = min(10, subset.height // 5)
                moving_avg = subset["rt_ms"].rolling_mean(
                    window_size=window, min_periods=1
                )

                fig5.add_trace(
                    go.Scatter(
                        x=subset["trial_order"].to_numpy(),
                        y=moving_avg.to_numpy(),
                        name=f"{resp} ç§»åŠ¨å¹³å‡(window={window})",
                        line=dict(dash="dash", width=2),
                        opacity=0.7,
                    )
                )

        fig5.show()


def create_summary_dataframe(
    df, your_data, rogers_ref, yes_intensity, no_intensity, overall_corr
):
    """åˆ›å»ºæ±‡æ€»æ•°æ®æ¡†"""

    summary_data = {
        "æŒ‡æ ‡": [
            "æ€»è¯•æ¬¡æ•°",
            "Yesååº”æ•°",
            "Yesæ¯”ä¾‹",
            "å¹³å‡ååº”æ—¶(ms)",
            "ååº”æ—¶æ ‡å‡†å·®(ms)",
            "ååº”æ—¶ä¸­ä½æ•°(ms)",
            "Yeså¹³å‡ååº”æ—¶(ms)",
            "Noå¹³å‡ååº”æ—¶(ms)",
            "æ•´ä½“å¼ºåº¦è¯„åˆ†",
            "Yeså¹³å‡å¼ºåº¦",
            "Noå¹³å‡å¼ºåº¦",
            "RT-å¼ºåº¦ç›¸å…³æ€§",
            "æ–‡çŒ®å¹³å‡RT(ms)",
            "æ–‡çŒ®Yesæ¯”ä¾‹",
            "RTå·®å¼‚(ms)",
            "Yesæ¯”ä¾‹å·®å¼‚",
        ],
        "æ•°å€¼": [
            df.height,
            df.filter(pl.col("response") == "yes").height,
            your_data["yes_proportion"],
            your_data["mean_rt"],
            df["rt_ms"].std(),
            df["rt_ms"].median(),
            your_data["yes_rt"],
            your_data["no_rt"],
            df["intensity"].mean(),
            np.mean(yes_intensity) if len(yes_intensity) > 0 else None,
            np.mean(no_intensity) if len(no_intensity) > 0 else None,
            overall_corr["correlation"][0],
            rogers_ref["mean_rt"],
            rogers_ref["yes_proportion"],
            your_data["mean_rt"] - rogers_ref["mean_rt"],
            your_data["yes_proportion"] - rogers_ref["yes_proportion"],
        ],
        "å•ä½": [
            "æ¬¡",
            "æ¬¡",
            "ç™¾åˆ†æ¯”",
            "ms",
            "ms",
            "ms",
            "ms",
            "ms",
            "åˆ†",
            "åˆ†",
            "åˆ†",
            "ç›¸å…³ç³»æ•°",
            "ms",
            "ç™¾åˆ†æ¯”",
            "ms",
            "ç™¾åˆ†æ¯”",
        ],
    }

    return pl.DataFrame(summary_data, strict=False)


# ä¸»å‡½æ•°
def main():
    """ä¸»å‡½æ•°"""

    print("è‡ªæˆ‘å‚ç…§ç¼–ç ä»»åŠ¡æ•°æ®åˆ†æç³»ç»Ÿ")
    print("=" * 50)

    file_path = Path(input("è¯·è¾“å…¥SRETæ•°æ®æ–‡ä»¶è·¯å¾„:\n").strip("'").strip()).resolve()
    df = pl.read_csv(file_path)

    target_blocks = ["Encoding"]
    block_col = "phase"

    # åˆ†ææ•°æ®
    analyze_self_reference_data(
        df,
        target_blocks,
        block_col,
    )


if __name__ == "__main__":
    main()
